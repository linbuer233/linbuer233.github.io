"use strict";(self.webpackChunkwebblog=self.webpackChunkwebblog||[]).push([[6710],{1041:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});var r=t(4848),s=t(8453);const a={title:"Pytorch-lightning \u7b14\u8bb0",date:new Date("2022-09-23T22:10:41.000Z"),authors:"lin",tags:["ML&DL"]},l="\u4ecb\u7ecd",i={id:"ML&DL/torchlight",title:"Pytorch-lightning \u7b14\u8bb0",description:"Pytorch Linghtning \u662f\u5728 pytorch \u57fa\u7840\u4e0a\u8fdb\u884c\u5c01\u88c5\u7684\u5e93\uff0c\u4e3a\u4e86\u8ba9\u7528\u6237\u4e13\u6ce8\u4e8e\u6838\u5fc3\u4ee3\u7801\u7684\u6784\u5efa\uff0c\u63d0\u4f9b\u8bb8\u591a\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u53ef\u4ee5\u8ba9\u5b9e\u9a8c\u66f4\u52a0\u9ad8\u6548\u3002",source:"@site/docs/ML&DL/torchlight.md",sourceDirName:"ML&DL",slug:"/ML&DL/torchlight",permalink:"/docs/ML&DL/torchlight",draft:!1,unlisted:!1,tags:[{inline:!0,label:"ML&DL",permalink:"/docs/tags/ml-dl"}],version:"current",frontMatter:{title:"Pytorch-lightning \u7b14\u8bb0",date:"2022-09-23T22:10:41.000Z",authors:"lin",tags:["ML&DL"]},sidebar:"tutorialSidebar",previous:{title:"\u6df1\u5ea6\u5b66\u4e60\u7528\u4e8e\u53f0\u98ce\u5f3a\u5ea6\u9884\u6d4b",permalink:"/docs/ML&DL/taifengQiangduDL"},next:{title:"\u5929\u6c14\u5b66\u539f\u7406",permalink:"/docs/category/\u5929\u6c14\u5b66\u539f\u7406"}},o={},d=[];function c(e){const n={code:"code",h1:"h1",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"\u4ecb\u7ecd",children:"\u4ecb\u7ecd"})}),"\n",(0,r.jsx)(n.p,{children:"Pytorch Linghtning \u662f\u5728 pytorch \u57fa\u7840\u4e0a\u8fdb\u884c\u5c01\u88c5\u7684\u5e93\uff0c\u4e3a\u4e86\u8ba9\u7528\u6237\u4e13\u6ce8\u4e8e\u6838\u5fc3\u4ee3\u7801\u7684\u6784\u5efa\uff0c\u63d0\u4f9b\u8bb8\u591a\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u53ef\u4ee5\u8ba9\u5b9e\u9a8c\u66f4\u52a0\u9ad8\u6548\u3002"}),"\n",(0,r.jsx)(n.h1,{id:"lightning",children:"Lightning"}),"\n",(0,r.jsx)(n.p,{children:"lightning \u5927\u81f4\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u7814\u7a76\u4ee3\u7801\uff08LightningModule\uff09\uff0c\u4e3b\u8981\u662f\u6a21\u578b\u7684\u7ed3\u6784\u3001\u8bad\u7ec3\u7b49\u90e8\u5206\uff0c"}),"\n",(0,r.jsx)(n.li,{children:"\u5de5\u7a0b\u4ee3\u7801\uff08Trainer\uff09\uff0c\u4ee3\u7801\u91cd\u590d\u6027\u9ad8\u7684\u90e8\u5206\uff0c\u6bd4\u5982\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c"}),"\n",(0,r.jsx)(n.li,{children:"\u975e\u5fc5\u8981\u4ee3\u7801\uff08Callbacks\uff09\uff0c\u6ca1\u6709\u76f4\u63a5\u7684\u5173\u7cfb\uff0c\u8d77\u8f85\u52a9\u7684\u4f5c\u7528\uff0c\u6bd4\u5982\u68af\u5ea6\u68c0\u67e5\uff0clog \u8f93\u51fa\u7b49\u3002"}),"\n"]}),"\n",(0,r.jsx)(n.h1,{id:"lightningmodule-\u7ec4\u4ef6",children:"LightningModule \u7ec4\u4ef6"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u6a21\u578b"}),"\n",(0,r.jsx)(n.li,{children:"\u6570\u636e\u5904\u7406"}),"\n",(0,r.jsx)(n.li,{children:"\u635f\u5931\u51fd\u6570"}),"\n",(0,r.jsx)(n.li,{children:"\u4f18\u5316\u5668"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u6b65\u9aa4"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"\u521d\u59cb\u5316\uff0c__ init __()"}),"\n",(0,r.jsx)(n.li,{children:"\u51c6\u5907\u6570\u636e"}),"\n",(0,r.jsx)(n.li,{children:"\u914d\u7f6e\u4f18\u5316\u5668"}),"\n",(0,r.jsx)(n.li,{children:"\u914d\u7f6e\u6d4b\u8bd5\u90e8\u5206"}),"\n",(0,r.jsx)(n.li,{children:"\u52a0\u8f7d\u6570\u636e"}),"\n",(0,r.jsx)(n.li,{children:"\u8bad\u7ec3"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"\u793a\u4f8b"}),"\n",(0,r.jsx)(n.p,{children:"pytorch \u7248\u672c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u8bad\u7ec3\u6d4b\u8bd5\u90e8\u5206"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            if args.dry_run:\n                break\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n"})}),"\n",(0,r.jsx)(n.p,{children:"Lightning \u7248\u672c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class LitClassifier(pl.LightningModule):\n    def __init__(self, hidden_dim=128, learning_rate=1e-3):\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.l1 = torch.nn.Linear(28 * 28, self.hparams.hidden_dim)\n        self.l2 = torch.nn.Linear(self.hparams.hidden_dim, 10)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.l1(x))\n        x = torch.relu(self.l2(x))\n        return x\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.cross_entropy(y_hat, y)\n        return loss\n\n    def validation_step(self, batch, batch_idx): # \u9a8c\u8bc1\u90e8\u5206\n        x, y = batch\n        y_hat = self(x)\n        loss = F.cross_entropy(y_hat, y)\n        self.log('valid_loss', loss)\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.cross_entropy(y_hat, y)\n        self.log('test_loss', loss)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n\n    @staticmethod  # \u58f0\u660e\u4e00\u4e2a\u9759\u6001\u65b9\u6cd5\n    def add_model_specific_args(parent_parser):\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n        parser.add_argument('--hidden_dim', type=int, default=128)\n        parser.add_argument('--learning_rate', type=float, default=0.0001)\n        return parser\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def cli_main():\n    pl.seed_everything(1234) # \u8fd9\u4e2a\u662f\u7528\u4e8e\u56fa\u5b9a seed \u7528\n\n    # args\n    parser = ArgumentParser()\n    parser = pl.Trainer.add_argparse_args(parser)\n    parser = LitClassifier.add_model_specific_args(parser)\n    parser = MNISTDataModule.add_argparse_args(parser)\n    args = parser.parse_args()\n\n    # data\n    dm = MNISTDataModule.from_argparse_args(args)\n\n    # model\n    model = LitClassifier(args.hidden_dim, args.learning_rate)\n\n    # training\n    trainer = pl.Trainer.from_argparse_args(args)\n    trainer.fit(model, datamodule=dm)\n\n    result = trainer.test(model, datamodule=dm)\n    print(result)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>i});var r=t(6540);const s={},a=r.createContext(s);function l(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);